%Computing counts, N1+ of several flavours of different sized n-grams.

The central requirement for computing probabilities under a Kneser-Ney
language model boils down to computing two types of counts: raw
frequencies of \ngrams and occurrence counts, quantifying in how many different contexts the \ngram has occurred.%
\footnote{The need such counts is not specific to Kneser Ney, indeed
  many other smoothing variants for \ngram LMs impose similar
  requirements and could be computed straightforwardly using the algorithms below.}
By electing to store the corpus directly in a suffix tree, we need to
provide mechanisms for computing these counts as they are needed based
on querying the data structure.

\begin{table}
\begin{align*}
c(\text{keep in the town})  & \quad 1 \\
c(\text{keep in the}) & \quad 2 \\
\nlplus{\text{keep in the} \Bigcdot} & \quad 2 \\ \hline
\nlplus{\Bigcdot \text{in the town}} & \quad 1\\
\nlplus{\Bigcdot \text{in the} \Bigcdot} & \quad 2 \\
\nlplus{\text{in the} \Bigcdot} & \quad 2 \\ \hline
\nlplus{\Bigcdot \text{the town}} & \quad 1\\
\nlplus{\Bigcdot \text{the} \Bigcdot} & \quad 4 \\
\nlplus{\text{the} \Bigcdot} & \quad 4  \\ \hline
\nlplus{\Bigcdot \text{town}} & \quad 1 \\
\nlplus{\Bigcdot \Bigcdot} & \quad 13 \\ % would be 14 but we exclude #$ right?
\nlplus{\Bigcdot} & \quad 9  % exclude $ right?
\end{align*}
\caption{Counts required for computing $P(\text{town} | \text{keep in
    the})$, and their values. Horizontal lines show the different
  stages in the backoff computation.}
\end{table}

Raw frequency counts are the simplest to compute, requiring first
identifying the node in the suffix tree labelled with the query
\ngram, from which we can read off the node's \emph{size}, defined as the
distance between its left and right bounds (corresponding to the
number of descendents under the node). To illustrate, consider
searching for \emph{the night} in  Figure~\ref{fig-suffix-tree}, which
matches a node with two descendents (labelled 19 and 12), and thus the
\ngram has count 2. This is a simple $\Order{1}$ operation once the
node has been identified.

More problematic are the occurrence counts, which come in several
flavours: with the dot to the right of the pattern, $\nlplus{\patdot}$,
to the left,  $\nlplus{\dotpat}$, and on both sides
$\nlplus{\dotpatdot}$. The first of these can be handled easily, by
querying the \emph{degree} of the matching node in the suffix tree. E.g., 
\emph{keep in} has two child nodes in  Figure~\ref{fig-suffix-tree},  
and thus there are two unique contexts in
which it can occur, $\nlplus{\emph{keep in~}\Bigcdot}=2$. This follows naturally from the suffix tree
construction, all descendent nodes correspond to larger \ngrams with
same prefix, and each child edge extends the \ngram with a different
subsequent symbol. 

\begin{algorithm}[th]
  \caption{Compute one-sided occurrence counts, $\nlplus{\dotpat}$ or $\nlplus{\patdot}$ for pattern $\alpha$ 
    \label{alg:n1plus}}
  \begin{algorithmic}[1]
    \Require{node $n$ in \CST $t$ matches $\alpha$}
    \Function{N1Plus}{$t, n, \alpha$} %\Comment{ $t$ is either forward or reverse \CST}
        \Let{$o$}{$0$} %\Comment{yielding $\nlplus{\patdot}$ or $\nlplus{\dotpat}$, respectively}
        %\If{$\leaf{t}{n} \, \wedge \, \depth{t}{n} = |\alpha|$}
        \If{$\depth{t}{n} = |\alpha|$}
          \Let{$o$}{$\degree{t}{n}$}
        \Else
          \Let{$o$}{$1$}
        \EndIf
      \State \Return{$o$}
    \EndFunction
  \end{algorithmic}
\label{alg-nlplus}
\end{algorithm}

A similar line of reasoning applies to computing
$\nlplus{\dotpat}$. Assuming we also have a suffix tree representing
the \emph{reversed corpus}, we can easily identify the reversed pattern
\emph{in keep} and query the degree for the matching node. This
approach is illustrated in Algorithm~\ref{alg-nlplus}, where we first
test if the node matches the pattern completely, i.e., its
\emph{depth} corresponds to the pattern length, in which case we use
the degree;\footnote{There are some corner cases involving sentinels \#
  and \$, which aren't counted in computing unique contexts.
  Such tests have been omitted from the algorithms for clarity, hereinafter. On publication the
  source code will be released with the complete implementation of the
  algorithms.}
otherwise the pattern is a prefix of the node, and
therefore can only be followed by a single unique symbol. 
For instance, \emph{the keep} partly matches an edge in
Figure~\ref{fig-suffix-tree} as it can only be followed by \emph{in}.
Finally, note that to compute $\nlplus{\dotpat}$ then $t$ must be the reversed \CST,
while supplying the forward \CST will yield $\nlplus{\patdot}$. Although
conceptually simple, using both reversed and forward suffix trees incurs double the storage overhead,
and, as we will show below, requires considerable additional search
overhead to find nodes matching each \ngram pattern in both suffix trees. We show later
how we can avoid the need for the reversed suffix tree, giving rise to
lower memory requirements and faster runtime.

The final component of the Kneser-Ney LM computation is
$\nlplus{\dotpatdot}$, the number of unique contexts consider symbols
on both sides of the pattern. 
Clearly this does not map naturally to a simple suffix tree operation,
requiring a more complex approach.



\begin{algorithm*}
  \caption{Compute two-sided occurrence counts, $\nlplus{\dotpatdot}$ 
    \label{alg:n1plusfb}}
  \begin{algorithmic}[1]
    \Require{$\nf$ is the node in the forward \CST $\tf$ matching pattern $\alpha$}
    \Require{$\nr$ is the node in the reverse \CST $\tr$ matching pattern $\alpha$}
    \Function{N1PlusFrontBack}{$\tf, \nf, \tr, \nr, \alpha$} 
        \Let{$o$}{$0$}
        %\If{$\leaf{\tf}{\nf} \, \vee \, \depth{\tf}{\nf} > |\alpha|$}   \Comment{leaves and patterns internal to an edge}
        \Let{$d$}{$\depth{\tf}{\nf} >$}   
        \If{$d > |\alpha|$}   \Comment{patterns internal to an edge}
          \Let{$o$}{$\nlplusfunc{\tr}{\nr}{\dotpat}$} \Comment{have only one right context}
        \Else
           \For{$\chf \gets \children{\tf}{\nf}$} 
              \Let{$s$}{$\edge{\tf}{\chf}{d+1}$} \Comment{find the first symbol on the edge label}
              \Let{$\chr$}{$\backwardsearch{\ar}{\lb{\nr}}{\rb{\nr}}{s}$} \Comment{find child node in reverse \CST}
              \Statex    \Comment{$\ar$ is the \CSA component of $\tr$}
              \Let{$o$}{$o + \nlplusfunc{\tr}{\chr}{\dotpat s}$}
            \EndFor
        \EndIf
      \State \Return{$o$}
    \EndFunction
  \end{algorithmic}
\end{algorithm*}




\subsection{Dual \CST Algorithm} 

Algorithm overview.

Include paragraph on computing the discounts.

\subsection{Complexity Analysis}

\section{Improved single \CST approach}

Just show N1+fb algo; leave rest to supporting material.
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "cstlm"
%%% End: 
