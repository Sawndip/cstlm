In this paper, we build  fast and compact high-order \ngram language models (LMs) using modern succinct data structures.
%
We show how to compactly index the text statistics needed by Kneser-Kney (KN) LMs 
to efficiently make the smoothed probabilities on the fly.
%
Importantly, the stored index for text statistics is kept intact for \ngram LMs with different orders, 
which allows to relax the Markov assumption made in these LMs by considering very large contexts.
%
At the core, the stored index makes use of compressed suffix structures including FM-index and wavelet trees.
%
Our comprehensive experiments show that the memory footprint of our high-order KN-LMs, which are infeasible to build using 
state-of-the-art LM toolkits due to memory constraints, is the same as that for low-order LMs while maintaining 
a reasonable query-time. 
