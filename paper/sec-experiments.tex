
\subsection{Datasets}
We used Europarl dataset and the data was numberized after tokenizing, splitting, and excluding xml markups. The first $10K$ sentences were used as the test data, and the last 80\% as the training data (See Table~\ref{fig:data}).

\begin{table}
\resizebox{1\columnwidth}{!}{
\begin{tabular}{ll|cc|c}
Language&&Size (MB)&Tokens (M)& Sentences (K)\\
\toprule 
Bulgarian&BG&36.11&8.53&329\\
Czech&CS&53.48&12.25&535\\
German&DE&171.80&44.07&1785 \\
English&EN&179.15&49.32&1815\\
Finnish&FI&145.32&32.85&1737\\
French&FR&197.68&53.82&1792\\
Hungarian&HU&52.53&12.02&527\\
Italian&IT&186.67&48.08&1703\\
Portuguese&PT&187.20&49.03&1737\\
\end{tabular}}
\caption{Tokens and sentence counts refer to the training partition. \trevor{Move to \supp}}\label{fig:data}
\end{table}
Figure~\ref{fig:data} is showing XXX.
\begin{figure}
\includegraphics[width=\columnwidth]{figures/german_pattern_size.pdf}
\caption{Number of successful queries across different pattern sizes from KN computation over the German test set, with unbounded $m$.}
\end{figure}\label{fig:germanpattern}

\paragraph{Perplexity}
We evaluated the perplexity across different languages and using \ngrams of varying order from $m=2$ to $\infty$ (unbounded), as shown on Figure~\ref{figure:pplx}.
Our results matched the perplexity results from \SRILM (for smaller values of $m$ in which \SRILM training was feasible, $m \le 10$).
Note that perplexity drops dramatically from $m=2\ldots5$ however the gains thereafter are modest for most languages.
Despite this, several large \ngram matches were found as illustrated in Figure~\ref{fig:germanpattern}, ranging in size up to a 34-gram match.
We speculate that the perplexity plateau is due to the simplistic Kneser-Ney discounting formula which is not designed for higher order \ngram LMs and appear to discount large \ngrams too aggressively. 
We leave further exploration of richer discounting techniques such as Modified Kneser-Ney \cite{chen_goodman} or the Sequence Memoizer \cite{wood_teh} to our future work.

%\subsection{Perplexity Evaluation}
\begin{figure}
\input{figures/fig-europarl-pplx-ngram}
\caption{Perplexity results on several Europarl languages for different \ngram sizes, $m=2\ldots10,15,20,\infty$.}
\label{figure:pplx}
\end{figure}

\begin{figure}
\includegraphics[width=\columnwidth]{figures/german_pattern_size.pdf}
\caption{Number of successful queries across different pattern sizes from KN computation over the German test set, with unbounded $m$.}
\label{fig:germanpattern}
\end{figure}

\paragraph{Runtime Requirements}
Figure~\ref{figure:space-time} shows the time and memory usage during training and querying with \SRILM default (optimized for time), and compact (optimized for space). 

\begin{figure}
\includegraphics[width=\columnwidth]{figures/Time-Space.pdf}
\caption{Time versus space tradeoffs measured on Europarl German (de) dataset, showing memory and time requirements for the four methods: CST single, CST dual, \SRILM, and \SRILM compact. Times were measured using a 10k sentence test set.}
\label{figure:space-time}
\end{figure}




%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "cstlm"
%%% End: 

